"""
EXAONE AI ê¸°ë°˜ ìì—°ì–´-SQL ë³€í™˜ ì„œë¹„ìŠ¤

Mock êµ¬í˜„ (íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜):
- ìì—°ì–´ ì§ˆë¬¸ì„ ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ ê·œì¹™ìœ¼ë¡œ SQL ë³€í™˜
- í´ë°±ìš©ìœ¼ë¡œ ì‚¬ìš©

ì‹¤ì œ API ì—°ë™ (Friendli.ai):
- EXAONE APIë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ NL-to-SQL ë³€í™˜
- Few-shot í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ ì •í™•í•œ SQL ìƒì„±
"""

import re
import os
import json
import requests
from typing import Optional, Dict, List, Any
from datetime import datetime, timedelta
from dotenv import load_dotenv

load_dotenv()


class ExaoneService:
    """EXAONE AI ìì—°ì–´-SQL ë³€í™˜ ì„œë¹„ìŠ¤"""

    # ì‚¬ì¶œ ì„±í˜• ë„ë©”ì¸ ê´€ë ¨ í‚¤ì›Œë“œ íŒ¨í„´
    PRODUCTION_KEYWORDS = [
        "ìƒì‚°", "ìƒì‚°ëŸ‰", "ì‚¬ì´í´", "ì£¼ê¸°", "ê°œìˆ˜",
        "ë¶ˆëŸ‰", "ê²°í•¨", "ì—ëŸ¬", "ì˜¤ë¥˜", "ë¶ˆëŸ‰ìœ¨", "ë¶ˆëŸ‰ë¥ ", "ë¶ˆëŸ‰ìœ í˜•",
        "ì˜¨ë„", "ì••ë ¥", "ë¬´ê²Œ", "ë¬´ê²Œ ì°¨ì´", "ì œí’ˆë¬´ê²Œ", "ë¬´ê²Œí¸ì°¨",
        "ì–‘í˜¸", "OK", "ì •ìƒ", "í†µê³¼", "ì„±ê³µ",
        "ê²€ì‚¬", "ìœ¡ì•ˆ", "ì‹œí—˜",
    ]

    EQUIPMENT_KEYWORDS = [
        "ì„¤ë¹„", "ì‚¬ì¶œê¸°", "ê¸°ê³„", "ì¥ë¹„", "ê¸°êµ¬",
        "ê¸ˆí˜•", "ëª°ë“œ", "ëª°ë”", "MOLD", "ëª°ë”ì •ë³´",
        "ì¬ë£Œ", "ì†Œì¬", "HIPS", "í”Œë¼ìŠ¤í‹±", "í‘ìƒ‰",
        "ë…¸ì¦", "ë°°ëŸ´", "ìŠ¤í¬ë¥˜", "íˆí„°",
        "ê°€ë™", "ì •ì§€", "ì ê²€", "ìœ ì§€ë³´ìˆ˜", "ìœ ì§€",
        "ì˜¨ë„", "ë°œì—´", "ì¿¨ë§", "ëƒ‰ê°",
    ]

    TIME_KEYWORDS = {
        "ì˜¤ëŠ˜": "CURDATE()",
        "ì–´ì œ": "DATE_SUB(CURDATE(), INTERVAL 1 DAY)",
        "ê·¸ì €ê»˜": "DATE_SUB(CURDATE(), INTERVAL 2 DAY)",
        "ì¬ì–´ì œ": "DATE_SUB(CURDATE(), INTERVAL 2 DAY)",
        "ë‚´ì¼": "DATE_ADD(CURDATE(), INTERVAL 1 DAY)",
        "ëª¨ë ˆ": "DATE_ADD(CURDATE(), INTERVAL 1 DAY)",
        "ì§€ë‚œì£¼": "DATE_SUB(CURDATE(), INTERVAL 7 DAY)",
        "ì§€ë‚œë‹¬": "DATE_SUB(CURDATE(), INTERVAL 30 DAY)",
        "ì´ë²ˆë‹¬": "DATE_FORMAT(CURDATE(), '%Y-%m-01')",
        "ì´ë²ˆì£¼": "DATE_SUB(CURDATE(), INTERVAL DAYOFWEEK(CURDATE())-1 DAY)",
        "ìµœê·¼7ì¼": "DATE_SUB(CURDATE(), INTERVAL 7 DAY)",
        "ìµœê·¼30ì¼": "DATE_SUB(CURDATE(), INTERVAL 30 DAY)",
    }

    @staticmethod
    def nl_to_sql(
        user_query: str,
        corrected_query: str,
        schema_info: Dict[str, Any],
        knowledge_base: Optional[List[str]] = None
    ) -> str:
        """
        ìì—°ì–´ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜ (Mock êµ¬í˜„)

        Args:
            user_query: ì›ë³¸ ì§ˆë¬¸ (ì˜ˆ: "ì˜¤ëŠ˜ ìƒì‚°ëŸ‰ì€?")
            corrected_query: ë³´ì •ëœ ì§ˆë¬¸ (ìš©ì–´ ì‚¬ì „ ì ìš©)
            schema_info: ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„° (í…Œì´ë¸”, ì»¬ëŸ¼ ì •ë³´)
            knowledge_base: ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤

        Returns:
            ìƒì„±ëœ SQL ì¿¼ë¦¬ ë¬¸ìì—´
        """
        try:
            # 1. ì§ˆë¬¸ ë¶„ì„
            intent = ExaoneService._analyze_intent(corrected_query)

            # 2. í•„ìš”í•œ í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì¶”ì¶œ
            table_info = ExaoneService._determine_table(
                corrected_query,
                intent,
                schema_info
            )

            # 3. SQL ìƒì„±
            sql = ExaoneService._generate_sql(
                corrected_query,
                intent,
                table_info,
                schema_info
            )

            return sql

        except Exception as e:
            raise ValueError(f"SQL ìƒì„± ì˜¤ë¥˜: {str(e)}")

    @staticmethod
    def _analyze_intent(query: str) -> Dict[str, Any]:
        """
        ì§ˆë¬¸ì˜ ì˜ë„ ë¶„ì„

        Returns:
            {
                "action": "select|aggregate|filter|trend",
                "has_date_filter": bool,
                "has_groupby": bool,
                "is_question": bool
            }
        """
        query_lower = query.lower()

        intent = {
            "action": "select",
            "has_date_filter": False,
            "has_groupby": False,
            "is_question": query.endswith("?"),
            "is_aggregation": False,
        }

        # ì§‘ê³„ í•¨ìˆ˜ ê°ì§€
        # 1. ëª…ì‹œì  ì§‘ê³„ í‚¤ì›Œë“œ
        if any(keyword in query_lower for keyword in ["í•©ê³„", "ì´", "í‰ê· ", "ìµœëŒ€", "ìµœì†Œ", "ëª‡ê°œ", "ëª‡"]):
            intent["is_aggregation"] = True
            intent["action"] = "aggregate"
        # 2. ìƒì‚°/ë¶ˆëŸ‰ ê´€ë ¨ í‚¤ì›Œë“œ (ì§‘ê³„ì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
        elif any(keyword in query_lower for keyword in ["ìƒì‚°ëŸ‰", "ìƒì‚°", "ë¶ˆëŸ‰ëŸ‰", "ë¶ˆëŸ‰"]):
            intent["is_aggregation"] = True
            intent["action"] = "aggregate"

        # ë‚ ì§œ í•„í„° ê°ì§€
        if any(keyword in query_lower for keyword in ExaoneService.TIME_KEYWORDS.keys()):
            intent["has_date_filter"] = True

        # ê·¸ë£¹í™” ê°ì§€
        if any(keyword in query_lower for keyword in ["ë¼ì¸ë³„", "ì œí’ˆë³„", "ì‹œê°„ë³„", "ì¼ë³„", "ê·¼ë¬´ì¡°ë³„", "ìœ í˜•ë³„"]):
            intent["has_groupby"] = True

        return intent

    @staticmethod
    def _determine_table(
        query: str,
        intent: Dict[str, Any],
        schema_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì§ˆë¬¸ì— í•„ìš”í•œ í…Œì´ë¸” ê²°ì • (ì‚¬ì¶œ ì„±í˜• ìŠ¤í‚¤ë§ˆ)

        Returns:
            {
                "table_name": str,
                "columns": List[str],
                "join_tables": List[str]
            }
        """
        query_lower = query.lower()
        table_name = "injection_cycle"
        columns = ["*"]
        join_tables = []

        # ì„¤ë¹„ ìœ ì§€ë³´ìˆ˜ ê´€ë ¨ ì§ˆë¬¸
        if any(keyword in query_lower for keyword in ["ìœ ì§€", "ìœ ì§€ë³´ìˆ˜", "ì ê²€", "ì •ë¹„"]):
            table_name = "equipment_maintenance"
            columns = ["*"]

        # ì—ë„ˆì§€ ê´€ë ¨ ì§ˆë¬¸
        elif any(keyword in query_lower for keyword in ["ì—ë„ˆì§€", "ì „ë ¥", "ì†Œë¹„", "ë¹„ìš©"]):
            table_name = "energy_usage"
            columns = ["*"]

        # ì¼ë³„ í†µê³„ ì§ˆë¬¸
        elif "ì¼ë³„" in query_lower or "ë‚ ì§œë³„" in query_lower:
            table_name = "daily_production"
            columns = ["*"]

        # ì‹œê°„ë³„ í†µê³„ ì§ˆë¬¸
        elif "ì‹œê°„ë³„" in query_lower or "ì‹œê°ë³„" in query_lower:
            table_name = "production_summary"
            columns = ["*"]

        # ê¸ˆí˜•/ì„¤ë¹„ ì •ë³´ ì§ˆë¬¸
        elif any(keyword in query_lower for keyword in ["ê¸ˆí˜•", "ëª°ë“œ", "ì„¤ë¹„", "ì‚¬ì¶œê¸°"]):
            # ê¸ˆí˜• ì •ë³´ëŠ” injection_cycleê³¼ í•¨ê»˜ ì¡°íšŒ
            table_name = "injection_cycle"
            columns = ["*"]
            join_tables = ["mold_info"]

        # ê¸°ë³¸ê°’: injection_cycle (ê°œë³„ ì‚¬ì´í´ ë°ì´í„°)
        else:
            table_name = "injection_cycle"
            columns = ["*"]

        return {
            "table_name": table_name,
            "columns": columns,
            "join_tables": join_tables
        }

    @staticmethod
    def _generate_sql(
        query: str,
        intent: Dict[str, Any],
        table_info: Dict[str, Any],
        schema_info: Dict[str, Any]
    ) -> str:
        """
        ì˜ë„ì™€ í…Œì´ë¸” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ SQL ìƒì„± (ì‚¬ì¶œ ì„±í˜• ë°ì´í„°)

        Rules:
        1. ì§‘ê³„(sum/count/avg)ê°€ í•„ìš”í•˜ë©´ SELECT SUM/COUNT/AVG
        2. ë‚ ì§œ í•„í„°ê°€ ìˆìœ¼ë©´ WHERE cycle_date = ...
        3. ê·¸ë£¹í™”ê°€ í•„ìš”í•˜ë©´ GROUP BY ...
        4. LIMIT 100 ê°•ì œ ì¶”ê°€
        """
        query_lower = query.lower()
        table_name = table_info["table_name"]

        # 1. SELECT ì ˆ êµ¬ì„±
        if intent["is_aggregation"]:
            select_clause = ExaoneService._build_aggregate_select(
                query, table_name
            )
        else:
            select_clause = "SELECT *"

        # 2. FROM ì ˆ
        from_clause = f"FROM {table_name}"

        # 3. WHERE ì ˆ êµ¬ì„± (ë‚ ì§œ, ë¶ˆëŸ‰ ìœ í˜• ë“±)
        where_clauses = []

        # ë‚ ì§œ í•„í„° (cycle_date ë˜ëŠ” date ì»¬ëŸ¼ ì‚¬ìš©)
        for time_keyword, date_expr in ExaoneService.TIME_KEYWORDS.items():
            if time_keyword in query_lower:
                if table_name == "injection_cycle":
                    where_clauses.append(f"cycle_date = {date_expr}")
                elif table_name == "daily_production":
                    where_clauses.append(f"production_date = {date_expr}")
                elif table_name == "production_summary":
                    where_clauses.append(f"DATE(summary_datetime) = {date_expr}")
                elif table_name == "energy_usage":
                    where_clauses.append(f"usage_date = {date_expr}")
                break

        # ë¶ˆëŸ‰ ìœ í˜• í•„í„°
        if "flash" in query_lower or "í”Œë˜ì‹œ" in query_lower:
            where_clauses.append("defect_type_id = 1")  # D001: Flash
        elif "void" in query_lower or "ê³µë™" in query_lower:
            where_clauses.append("defect_type_id = 2")  # D002: Void
        elif "weld" in query_lower or "ìš©ì ‘" in query_lower:
            where_clauses.append("defect_type_id = 3")  # D003: Weld Line
        elif "jetting" in query_lower:
            where_clauses.append("defect_type_id = 4")  # D004: Jetting
        elif "flow" in query_lower or "íë¦„" in query_lower:
            where_clauses.append("defect_type_id = 5")  # D005: Flow Mark

        # ìƒíƒœ í•„í„° (ì„±ê³µ/ë¶ˆëŸ‰)
        if "ì–‘í˜¸" in query_lower or "ì •ìƒ" in query_lower or "ì„±ê³µ" in query_lower:
            where_clauses.append("has_defect = FALSE")
        elif "ë¶ˆëŸ‰" in query_lower or "ê²°í•¨" in query_lower:
            where_clauses.append("has_defect = TRUE")

        where_clause = ""
        if where_clauses:
            where_clause = "WHERE " + " AND ".join(where_clauses)

        # 4. GROUP BY ì ˆ (ê·¸ë£¹í™”ê°€ í•„ìš”í•œ ê²½ìš°)
        group_by_clause = ""
        if intent["has_groupby"]:
            group_by_clause = ExaoneService._build_group_by(
                query, table_name
            )

        # 5. ORDER BY ì ˆ (ë‚ ì§œ ì—­ìˆœ ê¸°ë³¸)
        if table_name == "injection_cycle":
            order_by_clause = "ORDER BY id DESC"
        elif table_name == "daily_production":
            order_by_clause = "ORDER BY production_date DESC"
        elif table_name == "production_summary":
            order_by_clause = "ORDER BY summary_datetime DESC"
        else:
            order_by_clause = "ORDER BY id DESC"

        # 6. LIMIT ì ˆ (ê°•ì œ)
        limit_clause = "LIMIT 100"

        # SQL ì¡°í•©
        sql_parts = [select_clause, from_clause]
        if where_clause:
            sql_parts.append(where_clause)
        if group_by_clause:
            sql_parts.append(group_by_clause)
        sql_parts.append(order_by_clause)
        sql_parts.append(limit_clause)

        sql = " ".join(sql_parts) + ";"

        return sql

    @staticmethod
    def _build_aggregate_select(query: str, table_name: str) -> str:
        """
        ì§‘ê³„ í•¨ìˆ˜ë¥¼ í¬í•¨í•œ SELECT ì ˆ êµ¬ì„± (ì‚¬ì¶œ ì„±í˜•)

        ì˜ˆ:
        - "ì´ ì‚¬ì´í´ ìˆ˜" â†’ COUNT(*)
        - "í‰ê·  ë¬´ê²Œ" â†’ AVG(product_weight_g)
        - "ë¶ˆëŸ‰ë¥ " â†’ SUM(CASE WHEN has_defect THEN 1 ELSE 0 END) / COUNT(*) * 100
        """
        query_lower = query.lower()

        # ì‚¬ì´í´/ìƒì‚°ëŸ‰ ê´€ë ¨ ì§‘ê³„
        if any(kw in query_lower for kw in ["ì‚¬ì´í´", "ìƒì‚°", "ìƒì‚°ëŸ‰", "ê°œìˆ˜"]):
            if "ì¼ë³„" in query_lower or "ì‹œê°„ë³„" in query_lower:
                return "SELECT COUNT(*) as total_cycles, SUM(CASE WHEN has_defect = 0 THEN 1 ELSE 0 END) as good_count"
            else:
                return "SELECT COUNT(*) as total_cycles, COUNT(DISTINCT cycle_date) as cycle_dates"

        # ë¶ˆëŸ‰ ê´€ë ¨ ì§‘ê³„
        elif any(kw in query_lower for kw in ["ë¶ˆëŸ‰", "ê²°í•¨"]):
            if "ìœ¨" in query_lower or "rate" in query_lower:
                return "SELECT COUNT(*) as total, SUM(CASE WHEN has_defect = 1 THEN 1 ELSE 0 END) as defect_count, ROUND(SUM(CASE WHEN has_defect = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as defect_rate"
            else:
                return "SELECT SUM(CASE WHEN has_defect = 1 THEN 1 ELSE 0 END) as defect_count, COUNT(*) as total_cycles"

        # ë¬´ê²Œ ê´€ë ¨ ì§‘ê³„
        elif any(kw in query_lower for kw in ["ë¬´ê²Œ", "weight"]):
            if "í‰ê· " in query_lower:
                return "SELECT AVG(product_weight_g) as avg_weight, MIN(product_weight_g) as min_weight, MAX(product_weight_g) as max_weight, STDDEV(product_weight_g) as stddev_weight"
            else:
                return "SELECT AVG(product_weight_g) as avg_weight, COUNT(*) as total_cycles"

        # ì˜¨ë„ ê´€ë ¨ ì§‘ê³„
        elif any(kw in query_lower for kw in ["ì˜¨ë„"]):
            return "SELECT AVG(temp_nh) as avg_nh, AVG(temp_h1) as avg_h1, AVG(temp_h2) as avg_h2, AVG(temp_h3) as avg_h3, AVG(temp_h4) as avg_h4"

        # ì••ë ¥ ê´€ë ¨ ì§‘ê³„
        elif any(kw in query_lower for kw in ["ì••ë ¥"]):
            return "SELECT AVG(pressure_primary) as avg_primary, AVG(pressure_secondary) as avg_secondary, AVG(pressure_holding) as avg_holding"

        # ìœ ì§€ë³´ìˆ˜ ê´€ë ¨ ì§‘ê³„
        elif any(kw in query_lower for kw in ["ìœ ì§€", "ì ê²€", "ì •ë¹„"]):
            return "SELECT COUNT(*) as total_maintenance, MAX(maintenance_date) as last_maintenance, SUM(maintenance_hours) as total_hours"

        # ì—ë„ˆì§€ ê´€ë ¨ ì§‘ê³„
        elif any(kw in query_lower for kw in ["ì—ë„ˆì§€", "ì „ë ¥"]):
            return "SELECT SUM(power_consumption_kwh) as total_kwh, AVG(power_consumption_kwh) as avg_kwh"

        # ê¸°ë³¸ê°’
        return "SELECT COUNT(*) as total_records"

    @staticmethod
    def _build_group_by(query: str, table_name: str) -> str:
        """
        GROUP BY ì ˆ êµ¬ì„± (ì‚¬ì¶œ ì„±í˜•)

        ì˜ˆ:
        - "ë¶ˆëŸ‰ìœ í˜•ë³„ ë¶ˆëŸ‰" â†’ GROUP BY defect_type_id
        - "ì¼ë³„ ìƒì‚°" â†’ GROUP BY cycle_date
        - "ì‹œê°„ë³„ ìƒì‚°" â†’ GROUP BY HOUR(cycle_datetime)
        """
        query_lower = query.lower()

        grouping_rules = [
            ("ë¶ˆëŸ‰ìœ í˜•ë³„", "defect_type_id"),
            ("ë¶ˆëŸ‰ìœ í˜•ë³„ë¡œ", "defect_type_id"),
            ("ë¶ˆëŸ‰ë³„", "defect_type_id"),
            ("ë¶ˆëŸ‰ë³„ë¡œ", "defect_type_id"),
            ("ë‚ ì§œë³„", "cycle_date"),
            ("ë‚ ì§œë³„ë¡œ", "cycle_date"),
            ("ì¼ë³„", "cycle_date"),
            ("ì¼ë³„ë¡œ", "cycle_date"),
            ("ì‹œê°„ë³„", "HOUR(cycle_datetime)"),
            ("ì‹œê°„ë³„ë¡œ", "HOUR(cycle_datetime)"),
            ("ê¸ˆí˜•ë³„", "mold_id"),
            ("ê¸ˆí˜•ë³„ë¡œ", "mold_id"),
            ("ëª°ë“œë³„", "mold_id"),
            ("ëª°ë“œë³„ë¡œ", "mold_id"),
            ("ì¬ë£Œë³„", "material_id"),
            ("ì¬ë£Œë³„ë¡œ", "material_id"),
        ]

        for keyword, column in grouping_rules:
            if keyword in query_lower:
                return f"GROUP BY {column}"

        # ê¸°ë³¸ê°’: í…Œì´ë¸”ì— ë”°ë¼
        if table_name == "injection_cycle":
            return "GROUP BY cycle_date"
        elif table_name == "daily_production":
            return "GROUP BY production_date"
        elif table_name == "production_summary":
            return "GROUP BY DATE(summary_datetime)"
        elif table_name == "equipment_maintenance":
            return "GROUP BY machine_id"

        return ""


# ============================================================================
# ì‹¤ì œ EXAONE API ì—°ë™ (Friendli.ai)
# ============================================================================

class ChatGPTService:
    """
    OpenAI ChatGPT APIë¥¼ ì‚¬ìš©í•œ NL-to-SQL ë³€í™˜ ì„œë¹„ìŠ¤
    """

    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4")
    OPENAI_API_BASE_URL = "https://api.openai.com/v1/chat/completions"

    @staticmethod
    def nl_to_sql(
        user_query: str,
        corrected_query: str,
        schema_info: Dict[str, Any],
        knowledge_base: Optional[List[str]] = None
    ) -> str:
        """
        ChatGPT APIë¥¼ í˜¸ì¶œí•˜ì—¬ SQL ìƒì„±

        Args:
            user_query: ì›ë³¸ ì§ˆë¬¸
            corrected_query: ë³´ì •ëœ ì§ˆë¬¸
            schema_info: ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°
            knowledge_base: ë„ë©”ì¸ ì§€ì‹ ë¦¬ìŠ¤íŠ¸

        Returns:
            ìƒì„±ëœ SQL ì¿¼ë¦¬ ë¬¸ìì—´
        """
        if not ChatGPTService.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = ChatGPTService._build_prompt(
                corrected_query, schema_info, knowledge_base
            )

            # ChatGPT API í˜¸ì¶œ
            payload = {
                "model": ChatGPTService.OPENAI_MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ EXAONE ì‚¬ì¶œ ì„±í˜• ë¶„ì„ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

ì—­í• : 850í†¤ ì‚¬ì¶œê¸°ì˜ ìƒì‚° ë°ì´í„° ê¸°ë°˜ SQL ì¿¼ë¦¬ ìƒì„±, ë¶„ì„, ì¡°ì–¸ ì œê³µ

ê·œì¹™:
1. SELECT ì¿¼ë¦¬ë§Œ ìƒì„± (ì„¤ëª… ì—†ìŒ)
2. ë¹„êµ ì§ˆë¬¸("ë” ë§ë‹¤", "ì°¨ì´", "ë¹„êµ")ì´ ìˆìœ¼ë©´ ë‘ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ëª¨ë‘ ì¡°íšŒ
3. ë‚ ì§œ í•„í„°: ì˜¤ëŠ˜=CURDATE(), ì–´ì œ=DATE_SUB(CURDATE(), INTERVAL 1 DAY), ê·¸ì €ê»˜=DATE_SUB(CURDATE(), INTERVAL 2 DAY)
4. ì§‘ê³„í•¨ìˆ˜(SUM, AVG, COUNT) ì‚¬ìš©ì‹œ ëª…í™•í•œ ë³„ì¹­ ì œê³µ
5. GROUP BY ê·œì¹™:
   - "ë¶ˆëŸ‰ìœ í˜•ë³„" í‚¤ì›Œë“œ â†’ GROUP BY defect_type_id
   - "ì¼ë³„" í‚¤ì›Œë“œ â†’ GROUP BY cycle_date
   - "ì‹œê°„ë³„" í‚¤ì›Œë“œ â†’ GROUP BY HOUR(cycle_datetime)
   - "ê¸ˆí˜•ë³„" í‚¤ì›Œë“œ â†’ GROUP BY mold_id
6. ì˜ˆì‹œ:
   - "ì–´ì œ ë¶ˆëŸ‰ë¥ ?" â†’ SELECT COUNT(*) as total, SUM(CASE WHEN has_defect=1 THEN 1 ELSE 0 END) as defect_count, ROUND(SUM(CASE WHEN has_defect=1 THEN 1 ELSE 0 END)*100/COUNT(*), 2) as rate WHERE cycle_date=DATE_SUB(...)
   - "ì–´ì œ ë¶ˆëŸ‰ìœ í˜•ë³„ ë¶ˆëŸ‰?" â†’ SELECT defect_type_id, COUNT(*) as count FROM injection_cycle WHERE cycle_date=DATE_SUB(...) AND has_defect=1 GROUP BY defect_type_id
7. SQLë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ğŸš¨ ì¤‘ìš”: ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”!
- ì´ì „ì— "ì–´ì œ"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í–ˆìœ¼ë©´, ìƒˆë¡œìš´ ì§ˆë¬¸ì—ì„œ ë‚ ì§œë¥¼ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ **ë°˜ë“œì‹œ "ì–´ì œ"ë¥¼ ìœ ì§€**í•˜ì„¸ìš”.
- ì˜ˆ) ì´ì „: "ì–´ì œ ìƒì‚°ëŸ‰?", í˜„ì¬: "ë¶ˆëŸ‰ìœ í˜•ë³„?" â†’ "ì–´ì œ ë¶ˆëŸ‰ìœ í˜•ë³„ ë¶ˆëŸ‰"ìœ¼ë¡œ í•´ì„
- ë‚ ì§œë¥¼ ë°”ê¾¸ë ¤ë©´ ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ "ì˜¤ëŠ˜", "ê·¸ì €ê»˜" ë“±ì„ ë§í•´ì•¼ í•¨""",
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    },
                ],
                "temperature": 0.3,
                "max_tokens": 500,
            }

            response = requests.post(
                ChatGPTService.OPENAI_API_BASE_URL,
                headers={
                    "Authorization": f"Bearer {ChatGPTService.OPENAI_API_KEY}",
                    "Content-Type": "application/json",
                },
                json=payload,
                timeout=30,
            )

            # ì‘ë‹µ ê²€ì¦
            if response.status_code != 200:
                error_msg = response.text
                print(f"âŒ ChatGPT API ì˜¤ë¥˜ ({response.status_code}): {error_msg}")
                raise ValueError(f"ChatGPT API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")

            # SQL ì¶”ì¶œ
            result = response.json()
            if "choices" not in result or not result["choices"]:
                raise ValueError("API ì‘ë‹µì— choicesê°€ ì—†ìŠµë‹ˆë‹¤")

            generated_sql = result["choices"][0]["message"]["content"].strip()

            # SQL ì •ì œ
            generated_sql = ChatGPTService._clean_sql(generated_sql)

            print(f"âœ… ChatGPT SQL ìƒì„± ì„±ê³µ")
            print(f"   ìƒì„±ëœ SQL: {generated_sql[:100]}...")

            return generated_sql

        except requests.exceptions.Timeout:
            raise ValueError("ChatGPT ìš”ì²­ íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            raise ValueError(f"ChatGPT SQL ìƒì„± ì˜¤ë¥˜: {str(e)}")

    @staticmethod
    def _build_prompt(
        user_query: str,
        schema_info: Dict[str, Any],
        knowledge_base: Optional[List[str]] = None,
        context_info: str = ""
    ) -> str:
        """
        í”„ë¡¬í”„íŠ¸ êµ¬ì„±

        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            schema_info: ìŠ¤í‚¤ë§ˆ ì •ë³´
            knowledge_base: ë„ë©”ì¸ ì§€ì‹
            context_info: ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (ì‹œê°„ ì •ë³´ ë“±)
        """
        tables_info = ""
        if "tables" in schema_info:
            for table in schema_info["tables"]:
                tables_info += f"\n- {table['name']}: {table.get('description', 'N/A')}"
                for col in table.get("columns", []):
                    tables_info += f"\n  - {col['name']} ({col.get('type', 'unknown')})"

        if knowledge_base:
            knowledge_text = "\n".join([f"- {kb}" for kb in knowledge_base[:5]])
        else:
            knowledge_text = """- ìƒì‚°ëŸ‰(ì‚¬ì´í´ ìˆ˜)ëŠ” COUNT(*)ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤
- ë¶ˆëŸ‰ë¥ ì€ SUM(CASE WHEN has_defect=1 THEN 1 ELSE 0 END)*100/COUNT(*) ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤
- ë¶ˆëŸ‰ì€ has_defect=1, ì–‘í˜¸ëŠ” has_defect=0ìœ¼ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤
- ë¶ˆëŸ‰ ìœ í˜•ì€ defect_type_id (1=Flash, 2=Void, 3=WeldLine, ë“±)
- ì œí’ˆ ë¬´ê²ŒëŠ” product_weight_g (ëª©í‘œê°’: 252.5g Â±2g)
- ì˜¨ë„: temp_nh, temp_h1, temp_h2, temp_h3, temp_h4
- ì••ë ¥: pressure_primary, pressure_secondary, pressure_holding
- ì˜¤ëŠ˜ = CURDATE(), ì–´ì œ = DATE_SUB(CURDATE(), INTERVAL 1 DAY)"""

        # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í¬í•¨
        context_section = ""
        if context_info:
            context_section = f"""## ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
{context_info}

ì£¼ì˜: ì‚¬ìš©ìê°€ íŠ¹ë³„íˆ ë‚ ì§œë¥¼ ëª…ì‹œí•˜ì§€ ì•Šì•˜ë‹¤ë©´, ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

"""

        prompt = f"""{context_section}## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ (850í†¤ ì‚¬ì¶œê¸°)
{tables_info}

## ë„ë©”ì¸ ì§€ì‹
{knowledge_text}

## SQL ìƒì„± ê·œì¹™
1. MySQL ë¬¸ë²• ì‚¬ìš©
2. SELECT ì¿¼ë¦¬ë§Œ ìƒì„± (INSERT, UPDATE, DELETE ê¸ˆì§€)
3. ëª¨ë“  ì¿¼ë¦¬ì— LIMIT 100 ì¶”ê°€
4. ì§‘ê³„ í•¨ìˆ˜ ì‚¬ìš© ì‹œ ëª…í™•í•œ ë³„ì¹­ ì œê³µ
5. ì£¼ì„ ì œì™¸
6. ë¹„êµ ì§ˆë¬¸("ë” ë§ë‹¤", "ì°¨ì´", "ë¹„êµ")ì´ ìˆìœ¼ë©´ ë‘ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ëª¨ë‘ ì¡°íšŒ
7. íŠ¹ë³„íˆ ë‚ ì§œë¥¼ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ ì´ì „ ëŒ€í™”ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë”°ë¥´ì„¸ìš”

## ë‚ ì§œ ë§¤í•‘
- ì˜¤ëŠ˜: CURDATE()
- ì–´ì œ: DATE_SUB(CURDATE(), INTERVAL 1 DAY)
- ê·¸ì €ê»˜/ì¬ì–´ì œ: DATE_SUB(CURDATE(), INTERVAL 2 DAY)

## ì˜ˆì œ

ì˜ˆì‹œ 1) ë‹¨ìˆœ ì§‘ê³„: "ì˜¤ëŠ˜ ìƒì‚°ëŸ‰ì€?"
SELECT SUM(actual_quantity) as total_quantity FROM production_data WHERE DATE(production_date) = CURDATE() LIMIT 100;

ì˜ˆì‹œ 2) ë¹„êµ: "ì–´ì œì™€ ê·¸ì €ê»˜ ìƒì‚°ëŸ‰ì„ ë¹„êµí•´ì¤˜"
SELECT DATE(production_date) as date, SUM(actual_quantity) as total FROM production_data WHERE DATE(production_date) >= DATE_SUB(CURDATE(), INTERVAL 2 DAY) AND DATE(production_date) <= DATE_SUB(CURDATE(), INTERVAL 1 DAY) GROUP BY DATE(production_date) ORDER BY date DESC LIMIT 100;

ì˜ˆì‹œ 3) ë¼ì¸ë³„: "ë¼ì¸ë³„ ìƒì‚°ëŸ‰ì€?"
SELECT line_id, SUM(actual_quantity) as quantity FROM production_data WHERE DATE(production_date) = CURDATE() GROUP BY line_id ORDER BY line_id LIMIT 100;

## ì‚¬ìš©ì ì§ˆë¬¸
"{user_query}"

SQLë§Œ ìƒì„±í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”."""

        return prompt

    @staticmethod
    def generate_response(
        user_query: str,
        sql_result: Dict[str, Any]
    ) -> str:
        """
        SQL ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ìì—°ì–´ ë‹µë³€ ìƒì„±

        Args:
            user_query: ì›ë³¸ ì‚¬ìš©ì ì§ˆë¬¸
            sql_result: {"columns": [...], "rows": [...], "row_count": ...} í˜•íƒœì˜ SQL ê²°ê³¼

        Returns:
            ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ ë¬¸ìì—´
        """
        if not ChatGPTService.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·
            result_summary = ChatGPTService._format_result_for_llm(sql_result)

            prompt = f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
{user_query}

## ì¡°íšŒ ê²°ê³¼
{result_summary}

## ë‹µë³€ ê·œì¹™
1. ì‚¬ëŒì´ ëŒ€ë‹µí•˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê¸°
2. ìˆ«ìì—ëŠ” ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸(,) í¬í•¨
3. ë‚ ì§œëŠ” ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í‘œí˜„ (ì˜ˆ: 2026ë…„ 1ì›” 19ì¼, ì–´ì œ, ì˜¤ëŠ˜)
4. ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê·¸ ì´ìœ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…
5. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ ê¸°í˜¸ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê¸°
6. 2-3 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€

ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ë§Œ í•´ì£¼ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤."""

            # ChatGPT API í˜¸ì¶œ
            payload = {
                "model": ChatGPTService.OPENAI_MODEL,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt,
                    },
                ],
                "temperature": 0.7,  # ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´ë¥¼ ìœ„í•´ ì¡°ê¸ˆ ë†’ìŒ
                "max_tokens": 300,
            }

            response = requests.post(
                ChatGPTService.OPENAI_API_BASE_URL,
                headers={
                    "Authorization": f"Bearer {ChatGPTService.OPENAI_API_KEY}",
                    "Content-Type": "application/json",
                },
                json=payload,
                timeout=30,
            )

            # ì‘ë‹µ ê²€ì¦
            if response.status_code != 200:
                error_msg = response.text
                print(f"âŒ ChatGPT ì‘ë‹µ ìƒì„± ì˜¤ë¥˜ ({response.status_code}): {error_msg}")
                raise ValueError(f"ChatGPT ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {response.status_code}")

            result = response.json()
            if "choices" not in result or not result["choices"]:
                raise ValueError("API ì‘ë‹µì— choicesê°€ ì—†ìŠµë‹ˆë‹¤")

            response_text = result["choices"][0]["message"]["content"].strip()

            print(f"âœ… ChatGPT ì‘ë‹µ ìƒì„± ì„±ê³µ")
            print(f"   ìƒì„±ëœ ë‹µë³€: {response_text[:100]}...")

            return response_text

        except requests.exceptions.Timeout:
            raise ValueError("ChatGPT ì‘ë‹µ ìƒì„± íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            raise ValueError(f"ChatGPT ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")

    @staticmethod
    def generate_response_without_sql(user_query: str) -> str:
        """
        SQLì´ í•„ìš” ì—†ëŠ” ì¼ë°˜ ì§ˆë¬¸ì— ëŒ€í•œ ìì—°ì–´ ì‘ë‹µ ìƒì„±

        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸

        Returns:
            ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ ë¬¸ìì—´
        """
        if not ChatGPTService.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            prompt = f"""ë‹¹ì‹ ì€ EXAONE ì‚¬ì¶œ ì„±í˜• ë¶„ì„ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. 850í†¤ ì‚¬ì¶œê¸° ìƒì‚° ë°ì´í„° ì‹œìŠ¤í…œì˜ ì˜ë¦¬í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.

## ê·œì¹™
1. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€
2. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€
3. 2-3 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€
4. ì‚¬ì¶œ ì„±í˜• ìƒì‚° ë°ì´í„°ì™€ ê´€ë ¨ ìˆìœ¼ë©´ ê·¸ì— ë§ê²Œ ë‹µë³€

## ì‚¬ìš©ì ì§ˆë¬¸
{user_query}

ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ë§Œ í•´ì£¼ì„¸ìš”."""

            payload = {
                "model": ChatGPTService.OPENAI_MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ EXAONE ì‚¬ì¶œ ì„±í˜• ë¶„ì„ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

ì—­í• :
- 850í†¤ ì‚¬ì¶œê¸°ì˜ ìƒì‚° ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ë° ì¡°ì–¸
- ì¹œê·¼í•œ ëŒ€í™” ìƒëŒ€
- ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…

íŠ¹ì§•:
- ì •ì¤‘í•˜ê³  ì „ë¬¸ì 
- ì‚¬ì¶œ ì„±í˜•/ì œì¡° ë„ë©”ì¸ ì „ë¬¸ ì§€ì‹ í™œìš©
- ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ì œê³µ""",
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    },
                ],
                "temperature": 0.7,
                "max_tokens": 300,
            }

            response = requests.post(
                ChatGPTService.OPENAI_API_BASE_URL,
                headers={
                    "Authorization": f"Bearer {ChatGPTService.OPENAI_API_KEY}",
                    "Content-Type": "application/json",
                },
                json=payload,
                timeout=30,
            )

            # ì‘ë‹µ ê²€ì¦
            if response.status_code != 200:
                error_msg = response.text
                print(f"âŒ ChatGPT ì‘ë‹µ ìƒì„± ì˜¤ë¥˜ ({response.status_code}): {error_msg}")
                raise ValueError(f"ChatGPT ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {response.status_code}")

            result = response.json()
            if "choices" not in result or not result["choices"]:
                raise ValueError("API ì‘ë‹µì— choicesê°€ ì—†ìŠµë‹ˆë‹¤")

            response_text = result["choices"][0]["message"]["content"].strip()

            print(f"âœ… ChatGPT ì¼ë°˜ ëŒ€í™” ì‘ë‹µ ìƒì„± ì„±ê³µ")
            print(f"   ìƒì„±ëœ ë‹µë³€: {response_text[:100]}...")

            return response_text

        except requests.exceptions.Timeout:
            raise ValueError("ChatGPT ì‘ë‹µ ìƒì„± íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            raise ValueError(f"ChatGPT ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")

    @staticmethod
    def _format_result_for_llm(sql_result: Dict[str, Any]) -> str:
        """
        SQL ê²°ê³¼ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·

        Args:
            sql_result: {"columns": [...], "rows": [...], "row_count": ...}

        Returns:
            í¬ë§·ëœ ë¬¸ìì—´
        """
        columns = sql_result.get("columns", [])
        rows = sql_result.get("rows", [])
        row_count = sql_result.get("row_count", 0)

        if row_count == 0:
            return "ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ì»¬ëŸ¼ëª… ì •ë ¬
        result_lines = [f"ì¡°íšŒ í–‰ ìˆ˜: {row_count}ê°œ"]
        result_lines.append(f"ì»¬ëŸ¼: {', '.join(columns)}")
        result_lines.append("")

        # ê²°ê³¼ í–‰ë“¤
        if row_count <= 10:  # 10ê°œ ì´í•˜ë©´ ëª¨ë‘ í‘œì‹œ
            result_lines.append("ë°ì´í„°:")
            for i, row in enumerate(rows, 1):
                row_str = ", ".join([f"{col}: {row.get(col)}" for col in columns])
                result_lines.append(f"  í–‰ {i}: {row_str}")
        else:  # ë§ìœ¼ë©´ ìš”ì•½
            result_lines.append("ë°ì´í„° (ìƒìœ„ 5ê°œë§Œ í‘œì‹œ):")
            for i, row in enumerate(rows[:5], 1):
                row_str = ", ".join([f"{col}: {row.get(col)}" for col in columns])
                result_lines.append(f"  í–‰ {i}: {row_str}")
            result_lines.append(f"  ... ì™¸ {row_count - 5}ê°œ í–‰")

        return "\n".join(result_lines)

    @staticmethod
    def _clean_sql(sql: str) -> str:
        """SQL ì •ì œ"""
        # <sql> íƒœê·¸ ì œê±°
        if "<sql>" in sql:
            sql = sql.split("<sql>")[1].split("</sql>")[0]

        # ``` ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if "```sql" in sql:
            sql = sql.split("```sql")[1].split("```")[0]
        elif "```" in sql:
            sql = sql.split("```")[1].split("```")[0]

        sql = sql.strip()

        lines = []
        for line in sql.split("\n"):
            if "--" in line:
                line = line.split("--")[0]
            if "#" in line:
                line = line.split("#")[0]
            lines.append(line.strip())

        sql = " ".join([l for l in lines if l])

        select_pattern = r'SELECT\s+.*?(?:LIMIT\s+\d+)?'
        if "LIMIT" not in sql.upper():
            sql = sql.rstrip(";") + " LIMIT 100"

        if not sql.endswith(";"):
            sql += ";"

        return sql


class ExaoneAPIService:
    """
    ì‹¤ì œ EXAONE APIë¥¼ ì‚¬ìš©í•œ NL-to-SQL ë³€í™˜ ì„œë¹„ìŠ¤

    Friendli.aiì˜ EXAONE ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìì—°ì–´ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """

    EXAONE_API_BASE_URL = os.getenv(
        "EXAONE_API_BASE_URL",
        "https://api.friendli.ai/serverless/v1/chat/completions"
    )
    EXAONE_MODEL = os.getenv(
        "EXAONE_MODEL",
        "LGAI-EXAONE/K-EXAONE-236B-A23B"
    )
    EXAONE_TEMPERATURE = float(os.getenv("EXAONE_TEMPERATURE", "0.3"))
    EXAONE_MAX_TOKENS = int(os.getenv("EXAONE_MAX_TOKENS", "1000"))
    FRIENDLI_API_KEY = os.getenv("FRIENDLI_API_KEY")

    @staticmethod
    def nl_to_sql_api(
        user_query: str,
        corrected_query: str,
        schema_info: Dict[str, Any],
        knowledge_base: Optional[List[str]] = None
    ) -> str:
        """
        ì‹¤ì œ EXAONE APIë¥¼ í˜¸ì¶œí•˜ì—¬ SQL ìƒì„±

        Args:
            user_query: ì›ë³¸ ì§ˆë¬¸ (ì˜ˆ: "ì˜¤ëŠ˜ ìƒì‚°ëŸ‰ì€?")
            corrected_query: ë³´ì •ëœ ì§ˆë¬¸ (ìš©ì–´ ì‚¬ì „ ì ìš©)
            schema_info: ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°
            knowledge_base: ë„ë©”ì¸ ì§€ì‹ ë¦¬ìŠ¤íŠ¸

        Returns:
            ìƒì„±ëœ SQL ì¿¼ë¦¬ ë¬¸ìì—´

        Raises:
            ValueError: API í˜¸ì¶œ ì‹¤íŒ¨ ë˜ëŠ” SQL íŒŒì‹± ì˜¤ë¥˜
        """
        if not ExaoneAPIService.FRIENDLI_API_KEY:
            raise ValueError("FRIENDLI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # 1. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = ExaoneAPIService._build_prompt(
                corrected_query, schema_info, knowledge_base
            )

            # 2. EXAONE API í˜¸ì¶œ
            payload = {
                "model": ExaoneAPIService.EXAONE_MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ MySQL ì‚¬ì¶œ ì„±í˜• ë°ì´í„° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ì •í™•í•œ SQLë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ê·œì¹™:
1. SELECT ì¿¼ë¦¬ë§Œ ìƒì„± (ì„¤ëª… ì—†ìŒ)
2. ë¹„êµ ì§ˆë¬¸("ë” ë§ë‹¤", "ì°¨ì´", "ë¹„êµ")ì´ ìˆìœ¼ë©´ ë‘ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ëª¨ë‘ ì¡°íšŒ
3. ë‚ ì§œ í•„í„°: ì˜¤ëŠ˜=CURDATE(), ì–´ì œ=DATE_SUB(CURDATE(), INTERVAL 1 DAY)
4. ì§‘ê³„í•¨ìˆ˜(SUM, AVG, COUNT) ì‚¬ìš©ì‹œ ëª…í™•í•œ ë³„ì¹­ ì œê³µ
5. ë¶ˆëŸ‰ì€ has_defect ì»¬ëŸ¼, defect_type_id í•„ë“œë¡œ ì¡°íšŒ
6. SQLë§Œ ì¶œë ¥í•˜ì„¸ìš”.""",
                    },
                    {
                        "role": "user",
                        "content": prompt,
                    },
                ],
            }
            # max_tokensëŠ” ì„ íƒì‚¬í•­ì´ì§€ë§Œ, temperatureëŠ” ì„œë²„ì—ì„œ ê³ ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì œê±°

            response = requests.post(
                ExaoneAPIService.EXAONE_API_BASE_URL,
                headers={
                    "Authorization": f"Bearer {ExaoneAPIService.FRIENDLI_API_KEY}",
                    "Content-Type": "application/json",
                },
                json=payload,
                timeout=30,
            )

            # 3. ì‘ë‹µ ê²€ì¦
            if response.status_code != 200:
                error_msg = response.text
                print(f"âŒ EXAONE API ì˜¤ë¥˜ ({response.status_code}): {error_msg}")
                raise ValueError(f"EXAONE API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")

            # 4. SQL ì¶”ì¶œ
            result = response.json()
            if "choices" not in result or not result["choices"]:
                raise ValueError("API ì‘ë‹µì— choicesê°€ ì—†ìŠµë‹ˆë‹¤")

            generated_sql = result["choices"][0]["message"]["content"].strip()

            # 5. SQL ì •ì œ (ë§ˆí¬ë‹¤ìš´ ì œê±°, ì£¼ì„ ì œê±°)
            generated_sql = ExaoneAPIService._clean_sql(generated_sql)

            print(f"âœ… EXAONE API í˜¸ì¶œ ì„±ê³µ")
            print(f"   ì›ë³¸ ì§ˆë¬¸: {user_query}")
            print(f"   ìƒì„±ëœ SQL: {generated_sql[:100]}...")

            return generated_sql

        except requests.exceptions.Timeout:
            raise ValueError("EXAONE API íƒ€ì„ì•„ì›ƒ (30ì´ˆ ì´ˆê³¼)")
        except requests.exceptions.ConnectionError:
            raise ValueError("EXAONE API ì—°ê²° ì‹¤íŒ¨")
        except Exception as e:
            print(f"âŒ SQL ìƒì„± ì˜¤ë¥˜: {str(e)}")
            raise ValueError(f"SQL ìƒì„± ì˜¤ë¥˜: {str(e)}")

    @staticmethod
    def _build_prompt(
        user_query: str,
        schema_info: Dict[str, Any],
        knowledge_base: Optional[List[str]] = None
    ) -> str:
        """
        EXAONE APIë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±

        Few-shot ì˜ˆì œì™€ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
        """
        # ìŠ¤í‚¤ë§ˆ ì •ë³´ í¬ë§·íŒ…
        tables_info = ""
        if "tables" in schema_info:
            for table in schema_info["tables"]:
                tables_info += f"\n- {table['name']}: {table.get('description', 'N/A')}"
                for col in table.get("columns", []):
                    tables_info += f"\n  - {col['name']} ({col.get('type', 'unknown')})"

        # ë„ë©”ì¸ ì§€ì‹ í¬ë§·íŒ… (ì‚¬ì¶œ ì„±í˜•)
        if knowledge_base:
            knowledge_text = "\n".join([f"- {kb}" for kb in knowledge_base[:5]])
        else:
            knowledge_text = """- ìƒì‚°ëŸ‰(ì‚¬ì´í´ ìˆ˜)ëŠ” COUNT(*)ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤
- ë¶ˆëŸ‰ë¥ ì€ SUM(CASE WHEN has_defect=1 THEN 1 ELSE 0 END)*100/COUNT(*) ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤
- ë¶ˆëŸ‰ì€ has_defect=1, ì–‘í˜¸ëŠ” has_defect=0ìœ¼ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤
- ë¶ˆëŸ‰ ìœ í˜•ì€ defect_type_id (1=Flash, 2=Void, 3=WeldLine, 4=Jetting, 5=FlowMark, ë“±)
- ì œí’ˆ ë¬´ê²ŒëŠ” product_weight_g (ëª©í‘œê°’: 252.5g Â±2g)
- ì˜¨ë„: temp_nh, temp_h1, temp_h2, temp_h3, temp_h4, temp_mold_fixed, temp_mold_moving
- ì••ë ¥: pressure_primary, pressure_secondary, pressure_holding
- ì˜¤ëŠ˜ = CURDATE(), ì–´ì œ = DATE_SUB(CURDATE(), INTERVAL 1 DAY)"""

        prompt = f"""## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ (850í†¤ ì‚¬ì¶œê¸°)
ë‹¤ìŒì€ ì‚¬ì¶œ ì„±í˜• ìƒì‚° ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì…ë‹ˆë‹¤:{tables_info}

## ë„ë©”ì¸ ì§€ì‹
{knowledge_text}

## SQL ìƒì„± ê·œì¹™
1. MySQL ë¬¸ë²• ì‚¬ìš©
2. SELECT ì¿¼ë¦¬ë§Œ ìƒì„± (INSERT, UPDATE, DELETE ê¸ˆì§€)
3. ëª¨ë“  ì¿¼ë¦¬ì— LIMIT 100 ì¶”ê°€
4. ì§‘ê³„ í•¨ìˆ˜ ì‚¬ìš© ì‹œ ëª…í™•í•œ ë³„ì¹­ ì œê³µ
5. ORDER BYëŠ” ë°˜ë“œì‹œ SELECTëœ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
6. GROUP BYì™€ ORDER BY í•¨ê»˜ ì‚¬ìš© ì‹œ, ORDER BY ì»¬ëŸ¼ì€ GROUP BYì˜ ì»¬ëŸ¼ì´ê±°ë‚˜ ì§‘ê³„ í•¨ìˆ˜ì—¬ì•¼ í•¨
7. í•œê¸€ ì£¼ì„ì€ í¬í•¨í•˜ì§€ ì•Šê¸°

## Few-shot ì˜ˆì œ (ì‚¬ì¶œ ì„±í˜•)

### ì˜ˆì œ 1: ê¸°ë³¸ ì‚¬ì´í´ ìˆ˜
ì§ˆë¬¸: "ì˜¤ëŠ˜ ìƒì‚°ëŸ‰ì€?"
SQL: SELECT COUNT(*) as total_cycles FROM injection_cycle WHERE cycle_date = CURDATE() LIMIT 100;

### ì˜ˆì œ 2: ë¶ˆëŸ‰ìœ í˜•ë³„ ë¶ˆëŸ‰ ìˆ˜ (GROUP BY)
ì§ˆë¬¸: "ì–´ì œ ë¶ˆëŸ‰ìœ í˜•ë³„ ë¶ˆëŸ‰ì€?"
SQL: SELECT defect_type_id, COUNT(*) as count FROM injection_cycle WHERE cycle_date = DATE_SUB(CURDATE(), INTERVAL 1 DAY) AND has_defect = 1 GROUP BY defect_type_id ORDER BY count DESC LIMIT 100;

### ì˜ˆì œ 3: ë¶ˆëŸ‰ í•„í„°
ì§ˆë¬¸: "ì–´ì œ ë¶ˆëŸ‰ì€?"
SQL: SELECT COUNT(*) as defect_count FROM injection_cycle WHERE cycle_date = DATE_SUB(CURDATE(), INTERVAL 1 DAY) AND has_defect = 1 LIMIT 100;

### ì˜ˆì œ 4: ë¶ˆëŸ‰ë¥  ê³„ì‚°
ì§ˆë¬¸: "ì˜¤ëŠ˜ ë¶ˆëŸ‰ë¥ ì€?"
SQL: SELECT COUNT(*) as total, SUM(CASE WHEN has_defect = 1 THEN 1 ELSE 0 END) as defect_count, ROUND(SUM(CASE WHEN has_defect = 1 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as defect_rate FROM injection_cycle WHERE cycle_date = CURDATE() LIMIT 100;

### ì˜ˆì œ 5: í‰ê·  ë¬´ê²Œ
ì§ˆë¬¸: "ì§€ë‚œì£¼ ì œí’ˆ ë¬´ê²Œ í‰ê· ì€?"
SQL: SELECT AVG(product_weight_g) as avg_weight, MIN(product_weight_g) as min_weight, MAX(product_weight_g) as max_weight FROM injection_cycle WHERE cycle_date >= DATE_SUB(CURDATE(), INTERVAL 7 DAY) LIMIT 100;

### ì˜ˆì œ 6: ì˜¨ë„ ë²”ìœ„
ì§ˆë¬¸: "ì–´ì œ ë…¸ì¦ ì˜¨ë„ í‰ê· ì€?"
SQL: SELECT AVG(temp_nh) as nh, AVG(temp_h1) as h1, AVG(temp_h2) as h2, AVG(temp_h3) as h3, AVG(temp_h4) as h4 FROM injection_cycle WHERE cycle_date = DATE_SUB(CURDATE(), INTERVAL 1 DAY) LIMIT 100;

### ì˜ˆì œ 7: ì¼ë³„ í†µê³„
ì§ˆë¬¸: "ì§€ë‚œ 3ì¼ ì¼ë³„ ìƒì‚°ëŸ‰ì€?"
SQL: SELECT cycle_date, COUNT(*) as total_cycles, SUM(CASE WHEN has_defect = 0 THEN 1 ELSE 0 END) as good_count FROM injection_cycle WHERE cycle_date >= DATE_SUB(CURDATE(), INTERVAL 3 DAY) GROUP BY cycle_date ORDER BY cycle_date DESC LIMIT 100;

## ì‚¬ìš©ì ì§ˆë¬¸
"{user_query}"

ìœ„ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜í•˜ì„¸ìš”. SQLë§Œ ì¶œë ¥í•˜ê³  ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
        return prompt

    @staticmethod
    def _clean_sql(sql: str) -> str:
        """
        API ì‘ë‹µì—ì„œ SQLì„ ì¶”ì¶œí•˜ê³  ì •ì œí•©ë‹ˆë‹¤.

        - ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        - ì•ë’¤ ê³µë°± ì œê±°
        - ì£¼ì„ ì œê±°
        - ì»¬ëŸ¼ëª… ë„ì–´ì“°ê¸° ì •ê·œí™”
        - reasoning í…ìŠ¤íŠ¸ ì œê±°
        """
        # ë§ˆí¬ë‹¤ìš´ ì œê±°
        if "```sql" in sql:
            sql = sql.split("```sql")[1].split("```")[0]
        elif "```" in sql:
            sql = sql.split("```")[1].split("```")[0]

        # ì•ë’¤ ê³µë°± ì œê±°
        sql = sql.strip()

        # í•œê¸€ ì£¼ì„ ì œê±° (-- ë˜ëŠ” #)
        lines = []
        for line in sql.split("\n"):
            # -- ì£¼ì„ ì œê±°
            if "--" in line:
                line = line.split("--")[0]
            # # ì£¼ì„ ì œê±°
            if "#" in line:
                line = line.split("#")[0]
            lines.append(line.strip())

        sql = " ".join([l for l in lines if l])

        # ì»¬ëŸ¼ëª… ë„ì–´ì“°ê¸° ì •ê·œí™” (ì˜ˆ: "production _date" â†’ "production_date")
        sql = re.sub(r'\s+_', '_', sql)  # " _" â†’ "_"
        sql = re.sub(r'_\s+', '_', sql)  # "_ " â†’ "_"

        # ê°€ì¥ ê°•ë ¥í•œ ë°©ë²•: SELECT...LIMIT íŒ¨í„´ì„ ì¶”ì¶œ
        # SELECT ë¶€í„° LIMIT ìˆ«ìê¹Œì§€ë§Œ ì¶”ì¶œ (ê·¸ ì´í›„ í…ìŠ¤íŠ¸ ì œê±°)
        # íŒ¨í„´: SELECT ... FROM ... WHERE ... LIMIT number
        select_pattern = r'SELECT\s+.*?\s+LIMIT\s+\d+'
        match = re.search(select_pattern, sql, re.IGNORECASE | re.DOTALL)

        if match:
            sql = match.group(0)
            # ë§ˆì§€ë§‰ì— ì„¸ë¯¸ì½œë¡  ì¶”ê°€ (ì—†ìœ¼ë©´)
            if not sql.endswith(";"):
                sql += ";"
            return sql

        # ìœ„ íŒ¨í„´ì´ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ë°©ë²• ì‹œë„: LIMITê°€ ìˆëŠ” ê²½ìš°
        # LIMIT ì ˆì„ í¬í•¨í•œ ëª¨ë“  í…ìŠ¤íŠ¸ ì´í›„ ì œê±°
        limit_match = re.search(r'LIMIT\s+\d+\s*;?', sql, re.IGNORECASE)
        if limit_match:
            sql = sql[:limit_match.end()]
            if not sql.endswith(";"):
                sql += ";"
            return sql

        # LIMITê°€ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜ (ì•ˆì „ì¥ì¹˜)
        if not sql.endswith(";"):
            sql += ";"

        return sql


class GeminiService:
    """
    Google Gemini APIë¥¼ ì‚¬ìš©í•œ NL-to-SQL ë³€í™˜ ì„œë¹„ìŠ¤
    """

    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
    GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")
    GEMINI_API_BASE_URL = "https://generativelanguage.googleapis.com/v1beta/models"

    @staticmethod
    def nl_to_sql(
        user_query: str,
        corrected_query: str,
        schema_info: Dict[str, Any],
        knowledge_base: Optional[List[str]] = None
    ) -> str:
        """
        Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ SQL ìƒì„±

        Args:
            user_query: ì›ë³¸ ì§ˆë¬¸
            corrected_query: ë³´ì •ëœ ì§ˆë¬¸
            schema_info: ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°
            knowledge_base: ë„ë©”ì¸ ì§€ì‹ ë¦¬ìŠ¤íŠ¸

        Returns:
            ìƒì„±ëœ SQL ì¿¼ë¦¬ ë¬¸ìì—´
        """
        if not GeminiService.GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = ChatGPTService._build_prompt(
                corrected_query, schema_info, knowledge_base
            )

            # Gemini API í˜¸ì¶œ
            url = f"{GeminiService.GEMINI_API_BASE_URL}/{GeminiService.GEMINI_MODEL}:generateContent?key={GeminiService.GEMINI_API_KEY}"

            payload = {
                "contents": [
                    {
                        "role": "user",
                        "parts": [
                            {
                                "text": f"""ë‹¹ì‹ ì€ EXAONE ì‚¬ì¶œ ì„±í˜• ë¶„ì„ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

ì—­í• : 850í†¤ ì‚¬ì¶œê¸°ì˜ ìƒì‚° ë°ì´í„° ê¸°ë°˜ SQL ì¿¼ë¦¬ ìƒì„±, ë¶„ì„, ì¡°ì–¸ ì œê³µ

ê·œì¹™:
1. SELECT ì¿¼ë¦¬ë§Œ ìƒì„± (ì„¤ëª… ì—†ìŒ)
2. ë¹„êµ ì§ˆë¬¸("ë” ë§ë‹¤", "ì°¨ì´", "ë¹„êµ")ì´ ìˆìœ¼ë©´ ë‘ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ëª¨ë‘ ì¡°íšŒ
3. ë‚ ì§œ í•„í„°:
   - ì˜¤ëŠ˜=CURDATE()
   - ì–´ì œ=DATE_SUB(CURDATE(), INTERVAL 1 DAY)
   - ê·¸ì €ê»˜/ì¬ì–´ì œ=DATE_SUB(CURDATE(), INTERVAL 2 DAY)
4. ì§‘ê³„í•¨ìˆ˜(SUM, AVG, COUNT) ì‚¬ìš©ì‹œ ëª…í™•í•œ ë³„ì¹­ ì œê³µ
5. GROUP BY ê·œì¹™:
   - "ë¶ˆëŸ‰ìœ í˜•ë³„" í‚¤ì›Œë“œ â†’ GROUP BY defect_type_id
   - "ì¼ë³„" í‚¤ì›Œë“œ â†’ GROUP BY cycle_date
   - "ì‹œê°„ë³„" í‚¤ì›Œë“œ â†’ GROUP BY HOUR(cycle_datetime)
   - "ë¶ˆëŸ‰ë¥ ", "ìƒì‚°ëŸ‰" ê°™ì€ ìš”ì•½ ì§€í‘œ + "ë³„" ì—†ìœ¼ë©´ COUNT ì‚¬ìš© (GROUP BY ì—†ìŒ)
6. ì˜ˆì‹œ:
   - "ì–´ì œ ë¶ˆëŸ‰ë¥ ?" â†’ SELECT COUNT(*) as total, SUM(CASE WHEN has_defect=1 THEN 1 ELSE 0 END) as defect_count, ROUND(SUM(CASE WHEN has_defect=1 THEN 1 ELSE 0 END)*100/COUNT(*), 2) as rate WHERE cycle_date=DATE_SUB(...)
   - "ì–´ì œ ë¶ˆëŸ‰ìœ í˜•ë³„ ë¶ˆëŸ‰?" â†’ SELECT defect_type_id, COUNT(*) as count FROM injection_cycle WHERE cycle_date=DATE_SUB(...) AND has_defect=1 GROUP BY defect_type_id
7. SQLë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ğŸš¨ ì¤‘ìš”: ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ê·¸ê²ƒì„ ìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”!
- ì´ì „ì— "ì–´ì œ"ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í–ˆìœ¼ë©´, ìƒˆë¡œìš´ ì§ˆë¬¸ì—ì„œ ë‚ ì§œë¥¼ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ **ë°˜ë“œì‹œ "ì–´ì œ"ë¥¼ ìœ ì§€**í•˜ì„¸ìš”.
- ì˜ˆ) ì´ì „: "ì–´ì œ ìƒì‚°ëŸ‰?", í˜„ì¬: "ë¶ˆëŸ‰ìœ í˜•ë³„?" â†’ "ì–´ì œ ë¶ˆëŸ‰ìœ í˜•ë³„ ë¶ˆëŸ‰"ìœ¼ë¡œ í•´ì„
- ë‚ ì§œë¥¼ ë°”ê¾¸ë ¤ë©´ ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ "ì˜¤ëŠ˜", "ê·¸ì €ê»˜" ë“±ì„ ë§í•´ì•¼ í•¨

{prompt}"""
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.3,
                    "maxOutputTokens": 500,
                },
            }

            response = requests.post(
                url,
                json=payload,
                timeout=30,
            )

            # ì‘ë‹µ ê²€ì¦
            if response.status_code != 200:
                error_msg = response.text
                print(f"âŒ Gemini API ì˜¤ë¥˜ ({response.status_code}): {error_msg}")
                raise ValueError(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")

            # SQL ì¶”ì¶œ
            result = response.json()
            if "candidates" not in result or not result["candidates"]:
                raise ValueError("API ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤")

            generated_sql = result["candidates"][0]["content"]["parts"][0]["text"].strip()

            # SQL ì •ì œ
            generated_sql = ChatGPTService._clean_sql(generated_sql)

            print(f"âœ… Gemini SQL ìƒì„± ì„±ê³µ")
            print(f"   ìƒì„±ëœ SQL: {generated_sql[:100]}...")

            return generated_sql

        except requests.exceptions.Timeout:
            raise ValueError("Gemini ìš”ì²­ íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            raise ValueError(f"Gemini SQL ìƒì„± ì˜¤ë¥˜: {str(e)}")

    @staticmethod
    def generate_response(
        user_query: str,
        sql_result: Dict[str, Any]
    ) -> str:
        """
        SQL ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ìì—°ì–´ ë‹µë³€ ìƒì„±

        Args:
            user_query: ì›ë³¸ ì‚¬ìš©ì ì§ˆë¬¸
            sql_result: {"columns": [...], "rows": [...], "row_count": ...} í˜•íƒœì˜ SQL ê²°ê³¼

        Returns:
            ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ ë¬¸ìì—´
        """
        if not GeminiService.GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·
            result_summary = ChatGPTService._format_result_for_llm(sql_result)

            prompt = f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
{user_query}

## ì¡°íšŒ ê²°ê³¼
{result_summary}

## ë‹µë³€ ê·œì¹™
1. ì‚¬ëŒì´ ëŒ€ë‹µí•˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ê¸°
2. ìˆ«ìì—ëŠ” ì²œ ë‹¨ìœ„ êµ¬ë¶„ ê¸°í˜¸(,) í¬í•¨
3. ë‚ ì§œëŠ” ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í‘œí˜„ (ì˜ˆ: 2026ë…„ 1ì›” 19ì¼, ì–´ì œ, ì˜¤ëŠ˜)
4. ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê·¸ ì´ìœ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…
5. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ ê¸°í˜¸ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê¸°
6. 2-3 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€

ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ë§Œ í•´ì£¼ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ë¶ˆí•„ìš”í•©ë‹ˆë‹¤."""

            # Gemini API í˜¸ì¶œ
            url = f"{GeminiService.GEMINI_API_BASE_URL}/{GeminiService.GEMINI_MODEL}:generateContent?key={GeminiService.GEMINI_API_KEY}"

            payload = {
                "contents": [
                    {
                        "role": "user",
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 300,
                },
            }

            response = requests.post(
                url,
                json=payload,
                timeout=30,
            )

            # ì‘ë‹µ ê²€ì¦
            if response.status_code != 200:
                error_msg = response.text
                print(f"âŒ Gemini ì‘ë‹µ ìƒì„± ì˜¤ë¥˜ ({response.status_code}): {error_msg}")
                raise ValueError(f"Gemini ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {response.status_code}")

            result = response.json()
            if "candidates" not in result or not result["candidates"]:
                raise ValueError("API ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤")

            response_text = result["candidates"][0]["content"]["parts"][0]["text"].strip()

            print(f"âœ… Gemini ì‘ë‹µ ìƒì„± ì„±ê³µ")
            print(f"   ìƒì„±ëœ ë‹µë³€: {response_text[:100]}...")

            return response_text

        except requests.exceptions.Timeout:
            raise ValueError("Gemini ì‘ë‹µ ìƒì„± íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            raise ValueError(f"Gemini ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")

    @staticmethod
    def generate_response_without_sql(user_query: str) -> str:
        """
        SQLì´ í•„ìš” ì—†ëŠ” ì¼ë°˜ ì§ˆë¬¸ì— ëŒ€í•œ ìì—°ì–´ ì‘ë‹µ ìƒì„±

        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸

        Returns:
            ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ ë¬¸ìì—´
        """
        if not GeminiService.GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            prompt = f"""ë‹¹ì‹ ì€ EXAONE ì‚¬ì¶œ ì„±í˜• ë¶„ì„ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. 850í†¤ ì‚¬ì¶œê¸° ìƒì‚° ë°ì´í„° ì‹œìŠ¤í…œì˜ ì˜ë¦¬í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.

## ê·œì¹™
1. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€
2. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€
3. 2-3 ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€
4. ì‚¬ì¶œ ì„±í˜• ìƒì‚° ë°ì´í„°ì™€ ê´€ë ¨ ìˆìœ¼ë©´ ê·¸ì— ë§ê²Œ ë‹µë³€

## ì‚¬ìš©ì ì§ˆë¬¸
{user_query}

ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ë§Œ í•´ì£¼ì„¸ìš”."""

            # Gemini API í˜¸ì¶œ
            url = f"{GeminiService.GEMINI_API_BASE_URL}/{GeminiService.GEMINI_MODEL}:generateContent?key={GeminiService.GEMINI_API_KEY}"

            payload = {
                "contents": [
                    {
                        "role": "user",
                        "parts": [
                            {
                                "text": prompt
                            }
                        ]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.7,
                    "maxOutputTokens": 300,
                },
            }

            response = requests.post(
                url,
                json=payload,
                timeout=30,
            )

            if response.status_code != 200:
                error_msg = response.text
                print(f"âŒ Gemini ì¼ë°˜ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜ ({response.status_code}): {error_msg}")
                raise ValueError(f"Gemini ì¼ë°˜ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {response.status_code}")

            result = response.json()
            if "candidates" not in result or not result["candidates"]:
                raise ValueError("API ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤")

            response_text = result["candidates"][0]["content"]["parts"][0]["text"].strip()

            print(f"âœ… Gemini ì¼ë°˜ ì‘ë‹µ ìƒì„± ì„±ê³µ")
            print(f"   ìƒì„±ëœ ë‹µë³€: {response_text[:100]}...")

            return response_text

        except requests.exceptions.Timeout:
            raise ValueError("Gemini ì¼ë°˜ ì‘ë‹µ ìƒì„± íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            raise ValueError(f"Gemini ì¼ë°˜ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
